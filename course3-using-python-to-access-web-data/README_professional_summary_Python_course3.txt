ğŸ Python for Everybody â€” Course 3
Using Python to Access Web Data

Platform: Coursera â€” University of Michigan
Completed: âœ… 2025
Directory: course3-using-python-to-access-web-data

This course builds the foundation for retrieving, parsing, and interpreting data from the internet using Python.
I worked with regular expressions, sockets, HTTP, web scraping, XML, JSON, and REST APIs â€” making this course one of the most important bridges between basic Python and real-world data engineering.

The repository is organized module-by-module, with full documentation, code, screenshots, and downloaded data files preserved for reproducibility.

â¸»

ğŸ“ Folder Overview

course3-using-python-to-access-web-data/
â”‚
â”œâ”€â”€ module1-getting-started/
â”œâ”€â”€ module2-ch11-regular-expressions/
â”œâ”€â”€ module3-ch12-networks-and-sockets/
â”œâ”€â”€ module4-ch12-programs-that-surf-the-web/
â”œâ”€â”€ module5-ch13-web-services-and-xml/
â””â”€â”€ module6-ch13-JSON-and-the-REST-architecture/


Each folder includes:

Assignment instructions

My scripts

Screenshots and run results

Downloaded .html, .xml, .json files

My written explanations (.txt or README.md)

â¸»

ğŸ“˜ Module Summaries
ğŸ“— Module 1 â€” Getting Started

Introduces web concepts:

Understanding the HTTP request/response cycle

Using urllib to retrieve raw web pages

Printing and decoding text data from URLs

Foundations for scraping and parsing

This module established the baseline for all future assignments in the course.

ğŸ“˜ Module 2 â€” Chapter 11: Regular Expressions

Practiced extracting structured information using:

re.search()

re.findall()

Character classes

Quantifiers

Pattern matching across lines

Assignments involved reading files and using regex to sum values or extract meaningful tokens from text.

ğŸ“˜ Module 3 â€” Chapter 12: Networks and Sockets

Learned how to:

Create low-level socket connections

Send HTTP GET requests manually

Read server responses line by line

Strip HTML tags manually

Understand the origin of how browsers communicate

This reinforced how foundational protocols work beneath the surface of modern libraries.

ğŸ“˜ Module 4 â€” Chapter 12: Programs That Surf the Web

(This module includes your two fully documented assignments.)

1ï¸âƒ£ Following Links in HTML

Parse <a> tags using BeautifulSoup

Navigate through linked pages

Extract names in sequence

Follow a link at a specific position repeatedly

Final answer (June 2025 run): Shaiza

2ï¸âƒ£ Scraping Numbers from HTML

Parse <span> tags

Extract and convert numeric values

Compute their total sum

Foundation for XML/JSON parsing

This module introduces core scraping skills mirrored in real-world workflows.

ğŸ“˜ Module 5 â€” Chapter 13: Web Services and XML

Worked with:

XML structure and trees

ElementTree parsing

Attribute reading

Counting nodes

Summing values from XML fields

Assignments included processing provided XML files and extracting numeric totals.

ğŸ“˜ Module 6 â€” Chapter 13: JSON and the REST Architecture

Learned how to:

Request JSON from web APIs

Parse dictionaries and lists

Extract nested keys

Use REST endpoints

Process structured data dynamically

Assignments typically involved:

Summing counts in returned JSON

Retrieving place IDs

Calling API endpoints with parameters

â¸»

ğŸ§  Skills & Concepts Gained
âœ” HTTP & Web Architecture

Understanding how data travels between client and server.

âœ” Data Retrieval

Using urllib.request to fetch web content.

âœ” Web Scraping

Using BeautifulSoup to extract links, spans, and structured text.

âœ” Pattern Matching

Using regex to interpret and clean text data.

âœ” Socket Programming

Interacting with servers at a low level.

âœ” XML Parsing

Using ElementTree to navigate nodes and attributes.

âœ” JSON Parsing

Extracting values from REST responses.

âœ” API Fundamentals

Passing parameters, interpreting responses, and handling structured web data.

âœ” Clean Code & Documentation

All modules include:

Readable scripts

Commentary

Screenshots

Local data files

Summaries and analysis

â¸»

ğŸ”§ Tools & Libraries

Python 3

BeautifulSoup (bs4)

urllib.request

Regular Expressions (re)

ElementTree (XML)

JSON library

OnlineGDB for testing

Local .html, .json, .xml data files

â¸»

ğŸ“Œ Why This Course Matters

This course represents a transition from basic Python programming to real-world data handling.
It demonstrates the ability to:

Communicate with external services

Extract and analyze structured data

Build automated scripts

Work with APIs and scraping workflows

Handle formats used in modern software engineering

These skills directly support:

Data science

Simulation tech workflows

Backend development

API-based systems

Robotics & XR data pipelines

Machine learning preprocessing

â¸»

âœ… Status

Course 3 is 100% complete.
All assignments, code, data files, screenshots, and documentation are included and organized for clarity and reproducibility.